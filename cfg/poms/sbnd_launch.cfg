[global]
group      = sbnd
experiment = sbnd
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
version = v_override_me
quals   = override_me
fclfile = prodsingle_mu_100-1257MeV_fixposcontained_fixangle.fcl
mdprojectname = prodsingle_mu_100-1257MeV_fixposcontained_fixangle
mdprojectstage = override_me
basename= stage_override
baseoutdir=/pnfs/sbnd/scratch/sbndpro/dbrailsf_poms_test/test_full_flow/v06_80_01/%(mdprojectname)s
#19/07 DBrailsford
#Disable sam_dataset as we let POMS use %(dataset)s in the POMS interface.  This is automatically setup and used provided all of the dependent POMS stages are set up prior to launching the campaign
#sam_dataset = override_me
streamname = only
[env_pass]
IFDH_DEBUG = 1
SAM_EXPERIMENT=%(experiment)s
SAM_GROUP=%(group)s
SAM_STATION=%(experiment)s
[submit]
G          = %(group)s
N          = 5
#dataset     =
#resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE
resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED
generate-email-summary = True
#expected-lifetime      = 3h
#timeout                      = 2h
#OS                     = sl6
##disk                  = 10GB
#memory                 = 2000MB
f_1                    = /pnfs/sbnd/scratch/sbndpro/dbrailsf_poms_test/prescripts/sbndpoms_tfilemetadata_extractor.sh
f_2                    = /pnfs/sbnd/scratch/sbndpro/dbrailsf_poms_test/prescripts/sbndpoms_metadata_injector.sh
#f_3                    = /pnfs/sbnd/scratch/sbndpro/dbrailsf_poms_test/postscript/sbndpoms_ifdh_mkdir-p.sh

[job_setup]
debug       = True
find_setups = True
source_1    = /cvmfs/%(experiment)s.opensciencegrid.org/products/%(experiment)s/setup_%(experiment)s.sh
setup_1     = %(experiment)scode %(version)s -q %(quals)s

prescript_1 = sbndpoms_wrapperfcl_maker.sh --fclname %(fclfile)s --wrappername wrapper.fcl
prescript_2 = /bin/bash ${CONDOR_DIR_INPUT}/sbndpoms_metadata_injector.sh --inputfclname wrapper.fcl --mdfclname %(fclfile)s --mdprojectname %(mdprojectname)s --mdprojectstage %(mdprojectstage)s --mdprojectversion %(version)s --mdprojectsoftware sbndcode --mdproductionname 0.0 --mdproductiontype test --mdappversion %(version)s --mdfiletype mc --mdappfamily art --mdruntype physics --tfilemdjsonname hist_%(basename)s.root.json
prescript_3 = chmod +x ${CONDOR_DIR_INPUT}/sbndpoms_tfilemetadata_extractor.sh
prescript_4 = cat wrapper.fcl
postscript_1 = ls
#postscript_2 = /bin/bash ${CONDOR_DIR_INPUT}/sbndpoms_ifdh_mkdir-p.sh %(baseoutdir)s gsiftp

multifile   = True
#multifile   = True
#getconfig   = False
#ifdh_art    = False
[sam_consumer]
limit       = 1
appvers        = %(version)s
schema      = gsiftp
[executable]
name       = lar
arg_1      = -c
arg_2      = wrapper.fcl
arg_3      = -o
arg_4      = %(basename)s.root
arg_5      = -T 
arg_6      = hist_%(basename)s.root
arg_7      = -s 
#arg_8      = input_filename -- will be added by multifile loop...
[job_output]
addoutput   = %(basename)s.root
rename      = unique
dest        = %(baseoutdir)s
declare_metadata = True
metadata_extractor=sbndpoms_metadata_extractor.sh
add_location=True 

[job_output_1]
addoutput   = hist_%(basename)s.root
rename      = unique
dest        = %(baseoutdir)s
declare_metadata = True
#metadata_extractor=${CONDOR_DIR_INPUT}/sbndpoms_tfilemetadata_extractor.sh --inputfile %s --protojson hist_gen.root.json
metadata_extractor=${CONDOR_DIR_INPUT}/sbndpoms_tfilemetadata_extractor.sh
add_location=True 

[stage_gen]
job_setup.prescript_4 = sbndpoms_runnumber_injector.sh --fcl wrapper.fcl 
job_setup.prescript_5 = cat wrapper.fcl
# fake output dataset for POMS
job_output.add_to_dataset  = _poms_task
job_output.dataset_exclude = hist*
# turn off -s flag
executable.arg_7           = 
global.basename            = gen
global.mdprojectstage      = %(basename)s
job_setup.multifile        = False
job_output.dest            = %(baseoutdir)s/%(basename)s
job_output_1.dest          = %(baseoutdir)s/%(basename)s
[stage_g4]
global.fclfile        = standard_g4_%(experiment)s.fcl
global.basename       = g4
global.mdprojectstage = g4
submit.dataset        = %(dataset)s
job_output.dest       = %(baseoutdir)s/g4
job_output_1.dest     = %(baseoutdir)s/g4
# # if g4 only works onsite 
# submit.resource-provides= usage_model=OPPORTUNISTIC,DEDICATED
#
# # ...with extra cvmfs libraries:
# job_setup.prescript     = export LD_LIBRARY_PATH=/cvmfs/nova.opensciencegrid.org/externals/library_shim/v03.03/NULL/lib/sl6:$LD_LIBRARY_PATH
[stage_detsim]
global.basename       = detsim
global.mdprojectstage = detsim
global.fclfile        = standard_detsim_%(experiment)s.fcl
submit.dataset        = %(dataset)s
job_output.dest       = %(baseoutdir)s/detsim
job_output_1.dest     = %(baseoutdir)s/detsim
[stage_reco]
global.basename       = reco
global.mdprojectstage = reco
global.fclfile        = standard_reco_%(experiment)s_basic.fcl
submit.dataset        = %(dataset)s
job_output.dest       = %(baseoutdir)s/reco
job_output_1.dest     = %(baseoutdir)s/reco
[stage_anatree]
global.basename       = anatree
global.mdprojectstage = anatree
global.fclfile        = standard_anatree_%(experiment)s.fcl
submit.dataset        = %(dataset)s
job_output.dest       = %(baseoutdir)s/anatree
job_output_1.dest     = %(baseoutdir)s/anatree
#Disable the AROTROOT output
executable.arg_3      = 
executable.arg_4      = 
executable.arg_6      = %(basename)s.root
#19/07 DBrailsford
#This is a bit hacky right now.  I've asked marc about passing arguments to the metadata_extractor which would mean this isn't necessary.
job_setup.prescript_2 = /bin/bash ${CONDOR_DIR_INPUT}/sbndpoms_metadata_injector.sh --inputfclname wrapper.fcl --mdfclname %(fclfile)s --mdprojectname %(mdprojectname)s --mdprojectstage %(mdprojectstage)s --mdprojectversion %(version)s --mdprojectsoftware sbndcode --mdproductionname 0.0 --mdproductiontype test --mdappversion %(version)s --mdfiletype mc --mdappfamily art --mdruntype physics --tfilemdjsonname %(basename)s.root.json
#Point job_output towards a non-existent output as it isn't used for this stage
job_output.addoutput   = no_output.root
job_output_1.addoutput = %(basename)s.root

[stage_split]
global.basename = split
arg_3           =
arg_4           =
global.fclfile  = standard_streamsplit_%(experiment)s.fcl
submit.dataset  = %(dataset)s
[stage_merge]
global.basename = merge_%(streamname)s
global.fclfile  = standard_merge_%(experiment)s.fcl
submit.dataset  = %(dataset)s


